{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the libraries and the DataReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All outputs are visible\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "#Retina resolution for the plots\n",
    "from IPython.display import set_matplotlib_formats\n",
    "set_matplotlib_formats('retina')\n",
    "# All plots contained in the notebook\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.PlaylistDataReader import PlaylistDataReader\n",
    "from utils.logger import Logger\n",
    "from utils.config import clear, Configurator\n",
    "import argparse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlaylistDataReader: URM Matrix is being built...\n",
      "PlaylistDataReader: URM matrix built completed\n",
      "PlaylistDataReader: shape is (50446, 20635)\n",
      "PlaylistDataReader: UCM Matrix is being built...\n",
      "PlaylistDataReader: UCM matrix built completed\n",
      "PlaylistDataReader: shape is (50446, 25488)\n",
      "PlaylistDataReader: ICM Matrix is being built...\n",
      "PlaylistDataReader: ICM matrix built completed\n",
      "PlaylistDataReader: shape is (20635, 19412)\n",
      "PlaylistDataReader: URM_train and URM_test are being built...\n",
      "PlaylistDataReader: saving URM_train and URM_test\n"
     ]
    }
   ],
   "source": [
    "conf = Configurator(\"configs/item_knn_cbf.json\")\n",
    "\n",
    "data_reader = PlaylistDataReader()\n",
    "data_reader.build_URM()\n",
    "data_reader.build_UCM()\n",
    "data_reader.build_ICM()\n",
    "data_reader.split()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the model Folders and Auxilary Method Implementations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "import os\n",
    "# function for changing directory\n",
    "@contextmanager\n",
    "def working_directory(directory):\n",
    "    owd = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(directory)\n",
    "        yield directory\n",
    "    finally:\n",
    "        os.chdir(owd)\n",
    "\n",
    "def getModelName(file):\n",
    "    lst = file.split(\"/\")\n",
    "    return lst[1]\n",
    "def getSimName(file,saved=False):\n",
    "    if saved:\n",
    "        index = -3\n",
    "    else:\n",
    "        index = -4\n",
    "    simList = [\"asymmetric\",\"tversky\",\"cosine\",\"jaccard\",\"dice\"]\n",
    "    lst = file.split(\"_\")\n",
    "    if lst[index] in simList:\n",
    "        return lst[index]\n",
    "    else:\n",
    "        return \"default\"\n",
    "    \n",
    "def getUniqueModelList(fileList):\n",
    "    models = [getModelName(i) for i in fileList]\n",
    "    return list(set(models))\n",
    "\n",
    "def packageWithModel(fileList,saved=False):\n",
    "    model_file = []\n",
    "    for file in fileList:\n",
    "        added = (getModelName(file),file,getSimName(file,saved))\n",
    "        model_file.append(added)\n",
    "    return model_file\n",
    "\n",
    "import os      \n",
    "import re\n",
    "filter = re.compile(r'\\..+|.+\\.txt$')\n",
    "parameterFolder = \"tuned_parameters\"\n",
    "listOfFolders = os.listdir(parameterFolder)\n",
    "filteredDirPaths = [parameterFolder+\"/\"+i for i in listOfFolders if not filter.search(i)]\n",
    "saved_parameterFolder = \"saved_parameters\"\n",
    "listofParameters = os.listdir(saved_parameterFolder)\n",
    "filteredSavedParameters = [saved_parameterFolder + \"/\" + i for i in listofParameters if not filter.search(i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tuned_parameters/Slim_Elastic_Net_Recommender',\n",
       " 'tuned_parameters/UserKNNCFRecommender',\n",
       " 'tuned_parameters/SLIM_BPR_Recommender_mark1',\n",
       " 'tuned_parameters/ItemKNNCBFRecommender',\n",
       " 'tuned_parameters/P3_Alpha_Recommender',\n",
       " 'tuned_parameters/PureSVD',\n",
       " 'tuned_parameters/ItemTreeRecommender_offline',\n",
       " 'tuned_parameters/SLIM_BPR_Recommender_mark2',\n",
       " 'tuned_parameters/RP3_Beta_Recommender',\n",
       " 'tuned_parameters/ItemKNNCFRecommender']"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filteredDirPaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get All the Files and Categorize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = []\n",
    "best_model_parameters = []\n",
    "best_results = []\n",
    "files = []\n",
    "\n",
    "# get all the files\n",
    "for folder in filteredDirPaths:\n",
    "    with working_directory(folder):\n",
    "        filePaths = [folder +\"/\"+ i for i in os.listdir(\".\")]\n",
    "        files.extend(filePaths)\n",
    "        \n",
    "# Define error filter\n",
    "errorFilter = re.compile(r'Error.+')\n",
    "# Make it error free\n",
    "errorFilteredFiles = [i for i in files if not errorFilter.search(i)]\n",
    "bestModelFilter = re.compile(r'best_model$')\n",
    "modelFiles = [i for i in files if bestModelFilter.search(i)]\n",
    "parameterFilter = re.compile(r'best_parameters$')\n",
    "parameterFiles = [i for i in files if parameterFilter.search(i)]\n",
    "resultFilter = re.compile(r'best_result_test$')\n",
    "resultFiles = [i for i in files if resultFilter.search(i)]\n",
    "modelFiles_t = packageWithModel(modelFiles)\n",
    "parameterFiles_t = packageWithModel(parameterFiles)\n",
    "resultFiles_t = packageWithModel(resultFiles)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelsSoFar = getUniqueModelList(modelFiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the saved Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "resultFiles_saved = packageWithModel(filteredSavedParameters,saved=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('SLIM_BPR_Recommender_mark1_best_parameters',\n",
       "  'saved_parameters/SLIM_BPR_Recommender_mark1_best_parameters',\n",
       "  'default'),\n",
       " ('RP3_Beta_Recommender_best_parameters',\n",
       "  'saved_parameters/RP3_Beta_Recommender_best_parameters',\n",
       "  'default'),\n",
       " ('P3_Alpha_Recommender_best_parameters',\n",
       "  'saved_parameters/P3_Alpha_Recommender_best_parameters',\n",
       "  'default'),\n",
       " ('ItemKNNCBFRecommender_cosine_best_parameters',\n",
       "  'saved_parameters/ItemKNNCBFRecommender_cosine_best_parameters',\n",
       "  'cosine'),\n",
       " ('ItemTreeRecommender_offline_best_parameters',\n",
       "  'saved_parameters/ItemTreeRecommender_offline_best_parameters',\n",
       "  'default'),\n",
       " ('UserKNNCFRecommender_tversky_best_parameters',\n",
       "  'saved_parameters/UserKNNCFRecommender_tversky_best_parameters',\n",
       "  'tversky'),\n",
       " ('ItemKNNCFRecommender_cosine_best_parameters',\n",
       "  'saved_parameters/ItemKNNCFRecommender_cosine_best_parameters',\n",
       "  'cosine')]"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultFiles_saved"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find all the map values of the Best Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.OfflineDataLoader import OfflineDataLoader\n",
    "from models.KNN.User_KNN_CFRecommender import UserKNNCFRecommender\n",
    "from models.KNN.Item_KNN_CFRecommender import ItemKNNCFRecommender\n",
    "from models.KNN.Item_KNN_CBFRecommender import ItemKNNCBFRecommender\n",
    "from models.graph.P3AlphaRecommender import P3alphaRecommender\n",
    "from models.graph.RP3BetaRecommender import RP3betaRecommender\n",
    "from models.Slim_mark1.Cython.Slim_BPR_Cython import Slim_BPR_Recommender_Cython\n",
    "\n",
    "def printOutMapValues(modelList,URM,UCM,modelsSoFar):\n",
    "    map_dict = {i:dict() for i in modelsSoFar}\n",
    "    m = OfflineDataLoader()\n",
    "    for model in modelList:\n",
    "        folder = str(\"/\".join(model[1].split(\"/\")[:-1])+\"/\")\n",
    "        file = model[1].split(\"/\")[-1]\n",
    "        if model[0] == \"UserKNNCFRecommender\":\n",
    "            mod = UserKNNCFRecommender(URM)\n",
    "            mod.loadModel(folder_path=folder,file_name=file,verbose=False)\n",
    "            map_dict[model[0]][model[2]] = mod.MAP\n",
    "            print(model[0], model[2],mod.MAP)\n",
    "        elif model[0] == \"ItemKNNCFRecommender\":\n",
    "            mod = ItemKNNCFRecommender(URM)\n",
    "            mod.loadModel(folder_path=folder,file_name=file,verbose=False)\n",
    "            map_dict[model[0]][model[2]] = mod.MAP\n",
    "            print(model[0], model[2],mod.MAP)\n",
    "        elif model[0] == \"ItemKNNCBFRecommender\":\n",
    "            mod = ItemKNNCBFRecommender(URM,UCM)\n",
    "            mod.loadModel(folder_path=folder,file_name=file,verbose=False)\n",
    "            map_dict[model[0]][model[2]] = mod.MAP\n",
    "            print(model[0], model[2],mod.MAP)\n",
    "        elif model[0] == \"SLIM_BPR_Recommender_mark1\":\n",
    "            mod = Slim_BPR_Recommender_Cython(URM)\n",
    "            mod.loadModel(folder_path=folder,file_name=file,verbose=False)\n",
    "            map_dict[model[0]][model[2]] = mod.MAP\n",
    "            print(model[0], model[2],mod.MAP)\n",
    "        elif model[0] == \"RP3_Beta_Recommender\":\n",
    "            mod = RP3betaRecommender(URM)\n",
    "            mod.loadModel(folder_path=folder,file_name=file,verbose=False)\n",
    "            map_dict[model[0]][model[2]] = mod.MAP\n",
    "            print(model[0], model[2],mod.MAP)\n",
    "        elif model[0] == \"P3_Alpha_Recommender\":\n",
    "            mod = P3alphaRecommender(URM)\n",
    "            mod.loadModel(folder_path=folder,file_name=file,verbose=False)\n",
    "            map_dict[model[0]][model[2]] = mod.MAP\n",
    "            print(model[0], model[2],mod.MAP)\n",
    "        elif model[0] == \"PureSVD\":\n",
    "            mod = P3alphaRecommender(URM)\n",
    "            mod.loadModel(folder_path=folder,file_name=file,verbose=False)\n",
    "            map_dict[model[0]][model[2]] = mod.MAP\n",
    "            print(model[0], model[2],mod.MAP)\n",
    "        elif model[0] == \"Slim_Elastic_Net_Recommender\":\n",
    "            mod = P3alphaRecommender(URM)\n",
    "            mod.loadModel(folder_path=folder,file_name=file,verbose=False)\n",
    "            map_dict[model[0]][model[2]] = mod.MAP\n",
    "            print(model[0], model[2],mod.MAP)\n",
    "        elif model[0] == \"SLIM_BPR_Recommender_mark2\":\n",
    "            mod = P3alphaRecommender(URM)\n",
    "            mod.loadModel(folder_path=folder,file_name=file,verbose=False)\n",
    "            map_dict[model[0]][model[2]] = mod.MAP\n",
    "            print(model[0], model[2],mod.MAP)\n",
    "        \n",
    "    return map_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slim_Elastic_Net_Recommender default 8.99074074074074e-05\n",
      "UserKNNCFRecommender asymmetric 0.0945501676902241\n",
      "UserKNNCFRecommender tversky 0.09916801141660332\n",
      "UserKNNCFRecommender cosine 0.09308573721340364\n",
      "UserKNNCFRecommender jaccard 0.09870710122197038\n",
      "UserKNNCFRecommender dice 0.09811223900856646\n",
      "SLIM_BPR_Recommender_mark1 default 0.09533706067334359\n",
      "ItemKNNCBFRecommender jaccard 0.045217410068657087\n",
      "ItemKNNCBFRecommender asymmetric 0.04724069075963713\n",
      "ItemKNNCBFRecommender cosine 0.047233551996724604\n",
      "ItemKNNCBFRecommender dice 0.04515282665658843\n",
      "P3_Alpha_Recommender default 0.103057790721844\n",
      "PureSVD default 0.03208743994079095\n",
      "SLIM_BPR_Recommender_mark2 default 0.07908572412761378\n",
      "RP3_Beta_Recommender default 0.10393123242630366\n",
      "ItemKNNCFRecommender dice 0.09613278963529867\n",
      "ItemKNNCFRecommender jaccard 0.09579004448538653\n",
      "ItemKNNCFRecommender asymmetric 0.10151167776832949\n",
      "ItemKNNCFRecommender cosine 0.09949610989858927\n",
      "ItemKNNCFRecommender tversky 0.0916798676146386\n"
     ]
    }
   ],
   "source": [
    "a = printOutMapValues(resultFiles_t,data_reader.URM_train,data_reader.ICM,modelsSoFar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "saved = printOutMapValues(resultFiles_saved,data_reader.URM_train,data_reader.ICM,modelsSoFar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"ItemKNNCBFRecommender\": {\n",
      "        \"asymmetric\": 0.04724069075963713,\n",
      "        \"cosine\": 0.047233551996724604,\n",
      "        \"dice\": 0.04515282665658843,\n",
      "        \"jaccard\": 0.045217410068657087\n",
      "    },\n",
      "    \"ItemKNNCFRecommender\": {\n",
      "        \"asymmetric\": 0.10151167776832949,\n",
      "        \"cosine\": 0.09949610989858927,\n",
      "        \"dice\": 0.09613278963529867,\n",
      "        \"jaccard\": 0.09579004448538653,\n",
      "        \"tversky\": 0.0916798676146386\n",
      "    },\n",
      "    \"ItemTreeRecommender_offline\": {},\n",
      "    \"P3_Alpha_Recommender\": {\n",
      "        \"default\": 0.103057790721844\n",
      "    },\n",
      "    \"PureSVD\": {\n",
      "        \"default\": 0.03208743994079095\n",
      "    },\n",
      "    \"RP3_Beta_Recommender\": {\n",
      "        \"default\": 0.10393123242630366\n",
      "    },\n",
      "    \"SLIM_BPR_Recommender_mark1\": {\n",
      "        \"default\": 0.09533706067334359\n",
      "    },\n",
      "    \"SLIM_BPR_Recommender_mark2\": {\n",
      "        \"default\": 0.07908572412761378\n",
      "    },\n",
      "    \"Slim_Elastic_Net_Recommender\": {\n",
      "        \"default\": 8.99074074074074e-05\n",
      "    },\n",
      "    \"UserKNNCFRecommender\": {\n",
      "        \"asymmetric\": 0.0945501676902241,\n",
      "        \"cosine\": 0.09308573721340364,\n",
      "        \"dice\": 0.09811223900856646,\n",
      "        \"jaccard\": 0.09870710122197038,\n",
      "        \"tversky\": 0.09916801141660332\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(json.dumps(a,sort_keys=True, indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find all the max MAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def create_mapMax(model_dict):\n",
    "    model_map_list = []\n",
    "    import operator\n",
    "    for model in sorted(list(model_dict.keys())):\n",
    "        sorted_by_value = sorted(model_dict[model].items(), key=lambda kv: kv[1],reverse=True)\n",
    "        if len(sorted_by_value) != 0:\n",
    "            model_map_list.append((model,(sorted_by_value[0])))\n",
    "    return model_map_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ItemKNNCBFRecommender', ('asymmetric', 0.04724069075963713)),\n",
       " ('ItemKNNCFRecommender', ('asymmetric', 0.10151167776832949)),\n",
       " ('P3_Alpha_Recommender', ('default', 0.103057790721844)),\n",
       " ('PureSVD', ('default', 0.03208743994079095)),\n",
       " ('RP3_Beta_Recommender', ('default', 0.10393123242630366)),\n",
       " ('SLIM_BPR_Recommender_mark1', ('default', 0.09533706067334359)),\n",
       " ('SLIM_BPR_Recommender_mark2', ('default', 0.07908572412761378)),\n",
       " ('Slim_Elastic_Net_Recommender', ('default', 8.99074074074074e-05)),\n",
       " ('UserKNNCFRecommender', ('tversky', 0.09916801141660332))]"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = create_mapMax(a)\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profile Grouping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2293"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sps\n",
    "URM_train = sps.csr_matrix(data_reader.URM_train)\n",
    "\n",
    "profile_length = np.ediff1d(URM_train.indptr)\n",
    "\n",
    "block_size = int(len(profile_length)* (1/22))\n",
    "block_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_users = np.argsort(profile_length )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0, group size: 2293 average p.len 5.08, min 2, max 6\n",
      "Group 1, group size: 2293 average p.len 6.12, min 6, max 7\n",
      "Group 2, group size: 2293 average p.len 7.11, min 7, max 8\n",
      "Group 3, group size: 2293 average p.len 8.11, min 8, max 9\n",
      "Group 4, group size: 2293 average p.len 9.18, min 9, max 10\n",
      "Group 5, group size: 2293 average p.len 10.40, min 10, max 11\n",
      "Group 6, group size: 2293 average p.len 11.64, min 11, max 12\n",
      "Group 7, group size: 2293 average p.len 13.13, min 12, max 14\n",
      "Group 8, group size: 2293 average p.len 14.55, min 14, max 15\n",
      "Group 9, group size: 2293 average p.len 16.20, min 15, max 17\n",
      "Group 10, group size: 2293 average p.len 17.82, min 17, max 19\n",
      "Group 11, group size: 2293 average p.len 19.63, min 19, max 21\n",
      "Group 12, group size: 2293 average p.len 21.61, min 21, max 23\n",
      "Group 13, group size: 2293 average p.len 23.70, min 23, max 25\n",
      "Group 14, group size: 2293 average p.len 25.99, min 25, max 27\n",
      "Group 15, group size: 2293 average p.len 28.67, min 27, max 30\n",
      "Group 16, group size: 2293 average p.len 31.64, min 30, max 33\n",
      "Group 17, group size: 2293 average p.len 35.17, min 33, max 37\n",
      "Group 18, group size: 2293 average p.len 39.33, min 37, max 42\n",
      "Group 19, group size: 2293 average p.len 44.74, min 42, max 48\n",
      "Group 20, group size: 2293 average p.len 52.05, min 48, max 57\n",
      "Group 21, group size: 2293 average p.len 66.21, min 57, max 100\n"
     ]
    }
   ],
   "source": [
    "for group_id in range(0, 22):\n",
    "    \n",
    "    start_pos = group_id*block_size\n",
    "    end_pos = min((group_id+1)*block_size, len(profile_length))\n",
    "    \n",
    "    users_in_group = sorted_users[start_pos:end_pos]\n",
    "    \n",
    "    users_in_group_p_len = profile_length[users_in_group]\n",
    "    \n",
    "    print(\"Group {}, group size: {} average p.len {:.2f}, min {}, max {}\".format(group_id,len(users_in_group),\n",
    "        users_in_group_p_len.mean(), users_in_group_p_len.min(), users_in_group_p_len.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Slim_Elastic_Net_Recommender: Loading model from file 'saved_models/training/Slim_Elastic_Net_Recommender'\n",
      "Slim_Elastic_Net_Recommender: Loading complete\n"
     ]
    }
   ],
   "source": [
    "from models.Slim_mark2.Cython.Slim_BPR_Cython import Slim_BPR_Recommender_Cython\n",
    "from models.Slim_ElasticNet.SlimElasticNetRecommender import SLIMElasticNetRecommender\n",
    "t = SLIMElasticNetRecommender(data_reader.URM_train)\n",
    "m = OfflineDataLoader()\n",
    "fold ,file = m.get_model(SLIMElasticNetRecommender.RECOMMENDER_NAME)\n",
    "t.loadModel(folder_path = fold, file_name=file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<20635x20635 sparse matrix of type '<class 'numpy.float32'>'\n",
       "\twith 3538443 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.W_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
